{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e92b7b7",
   "metadata": {},
   "source": [
    "This is the perfect moment to pause. You have built a \"Developer's Cheat Sheet\" in your head.\n",
    "\n",
    "Here is the **Master Summary** of everything you have learned in our lessons. This covers the entire Scikit-Learn workflow.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. The Algorithms (The \"Brains\")\n",
    "\n",
    "We covered **5 Major Algorithms** across 3 categories:\n",
    "\n",
    "| Algorithm | Type | Use Case | Example |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Linear Regression** | Supervised (Regression) | Predicting **Numbers** | Salary, House Price |\n",
    "| **Logistic Regression** | Supervised (Classification) | Predicting **Categories** | Iris Species, Spam/Not Spam |\n",
    "| **Decision Tree** | Supervised (Classification) | Predicting with **Rules** (If/Else) | Iris (Visualized as a chart) |\n",
    "| **Random Forest** | Supervised (Ensemble) | Stronger Prediction (100 Trees voting) | Iris (High accuracy) |\n",
    "| **K-Means** | Unsupervised (Clustering) | Finding **Groups** (No Labels) | Grouping flowers without names |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. The Workflow (The \"Steps\")\n",
    "\n",
    "Every project followed this exact path:\n",
    "\n",
    "1.  **Prepare Data:** `X` (Features/Input) and `y` (Target/Answer).\n",
    "2.  **Split Data:**\n",
    "    *   `train_test_split(X, y, test_size=0.2, random_state=42)`\n",
    "    *   *Why?* To create a \"Textbook\" (Train) and an \"Exam\" (Test).\n",
    "3.  **Initialize:** `model = AlgorithmName()`\n",
    "4.  **Train:** `model.fit(X_train, y_train)`\n",
    "5.  **Predict:** `predictions = model.predict(X_test)`\n",
    "6.  **Save/Load:** `joblib.dump()` and `joblib.load()` (For web apps).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Hyperparameters (The \"Knobs\" & \"Settings\")\n",
    "\n",
    "These are the settings we tweaked to change how the model learns:\n",
    "\n",
    "*   **`test_size=0.2`**: Used in splitting. Means \"Keep 20% of data for the exam.\"\n",
    "*   **`random_state=42`**: Ensures the random shuffle is the **same** every time (so we get consistent results).\n",
    "*   **`max_depth`**: Used in **Decision Trees**. Limits how many questions the tree can ask (Prevents overfitting).\n",
    "*   **`n_estimators`**: Used in **Random Forest**. Decides how many trees to build (e.g., 100).\n",
    "*   **`n_clusters`**: Used in **K-Means**. Tells the computer how many groups to find.\n",
    "*   **`cv=5`**: Used in **GridSearchCV**. Means \"Cross Validation\" (Split the training data 5 times to double-check accuracy).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Metrics (The \"Report Card\")\n",
    "\n",
    "How did we check if the model was good?\n",
    "\n",
    "*   **MAE (Mean Absolute Error):** For Regression. \"On average, the model is wrong by X points.\"\n",
    "*   **Accuracy Score:** For Classification. \"The model got 95% of questions right.\"\n",
    "*   **Confusion Matrix:** A grid showing exactly where the model made mistakes (e.g., predicted 'Setosa' but it was 'Versicolor').\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Important Methods & Attributes\n",
    "\n",
    "These are the special commands you learned:\n",
    "\n",
    "*   **`.fit(X, y)`**: The command to start training.\n",
    "*   **`.predict(X)`**: The command to get answers.\n",
    "*   **`.feature_importances_`**: (Random Forest) Shows which columns are the \"Kings\" (most important).\n",
    "*   **`.labels_`**: (K-Means) The group numbers assigned to data.\n",
    "*   **`.best_params_`**: (GridSearch) The best settings found (e.g., `{'n_estimators': 100}`).\n",
    "*   **`.best_score_`**: (GridSearch) The accuracy of those best settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab778f",
   "metadata": {},
   "source": [
    "# max_iter\n",
    "\n",
    "#### In LogisticRegression(max_iter=1000) from scikit-learn, the parameter max_iter means:\n",
    "\n",
    "‚úÖ Maximum number of iterations allowed for the optimization algorithm\n",
    "\n",
    "Logistic regression in scikit-learn is solved using an iterative optimization method (like LBFGS, liblinear, saga, or newton-cg, depending on solver=). These algorithms repeatedly update the model coefficients until they converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a897be29",
   "metadata": {},
   "source": [
    "# ‚úÖ n_estimators\n",
    "\n",
    "This means:\n",
    "\n",
    "The number of decision trees in the random forest.\n",
    "\n",
    "n_estimators=100 ‚Üí The forest has 100 trees.\n",
    "\n",
    "More trees generally improve performance but increase training time.\n",
    "\n",
    "Typical values: 100‚Äì300 for most tasks, sometimes more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f4924",
   "metadata": {},
   "source": [
    "## üé≤ random_state\n",
    "\n",
    "random_state is simply a seed for the random number generator used by the algorithm.\n",
    "\n",
    "Random forests introduce randomness in:\n",
    "\n",
    "bootstrapping samples\n",
    "\n",
    "selecting subsets of features at each split\n",
    "\n",
    "Setting random_state ensures:\n",
    "\n",
    "üîÅ Reproducibility\n",
    "\n",
    "You get the same exact result every time you run the code.\n",
    "\n",
    "If you don‚Äôt set it:\n",
    "\n",
    "results will differ slightly each run because randomness changes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
